# +
#at 32gb ram & 16cpu this takes around 1hr to run
library(tidyverse)
library(raster)
library(sp)
library(sf)
library(dplyr) # data manipulation
#load in functions
source("SDHMfunctions.R")
#The data must be in EPSG 5070. The proj4string below is for 5070, if you are running this script in the cloud you must use proj4
proj <- "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs "
#Load in Utah 1km bounds - modelling extent
temp <- raster("/vsicurl/https://storage.googleapis.com/predictors_public/bounds/1km_template.tif")
#Load in Utah Fnet
fnetSF <-st_read("/vsicurl/https://storage.googleapis.com/predictors_public/bounds/km1_fnet.geojson", crs = proj)
#Load in Utah extent simple feature
blob <- st_read("https://storage.googleapis.com/predictors_public/bounds/huc_aea.geojson")
st_crs(blob) <- proj
#Set Extent
utext <- extent(c(-1610897,-1059966,1591940,2274654))
temp <- crop(temp, utext)
#the 'queryBiobase' code will not run outside of my virtual machine, please replace with your species data
pointData <- queryBiobase("ybcu") #could be a CSV
#They are in the projection 5070, and so must be anything you replace them with.
#The dataset must have 3 columns.
#The first column is not used in these functions. But could be a 'keep' column to filter off of
#The second column must be X (longitude)
#The third column must be Y (latitude)
head(pointData)
coords <- colnames(head(pointData)[,2:3])
#They are in the projection 5070, please set x&y coords accordingly
pointSF <- st_as_sf(pointData, coords = coords, crs = proj)
head(pointSF)
#Make a dataframe of presence & psuedo abs
#Needs the points simple feature, the blob geojson, and the template raster
pointPseudo <- pseudoFunction(pointSF, blob, temp)
head(pointPseudo) #x&y columns always lat/long
#Make your list of rasters from the document found here (lists can be any length greater than 1):
# https://storage.googleapis.com/predictors_structure/structure.csv
rasterList <- c("terrestrial/gradientmetrics/topo/1km/gm_allvars_topo_ut.tif",
"terrestrial/landfire/topo/1km/lf_allvars_topo_ut.tif",
"terrestrial/landfire/veg/1km/lf_allvars_veg_ut.tif",
"terrestrial/usfws/km_1/usfws_allvars_clim_ut.tif",
"terrestrial/usfws/km_1/usfws_allvars_hydro_ut.tif",
"terrestrial/usfws/km_1/usfws_allvars_veg_ut.tif")
#1000 random points within the state of utah have been provided as a placeholder
pointData <- read.csv("randompoints.csv")
#They are in the projection 5070, and so must be anything you replace them with.
#The dataset must have 3 columns.
#The first column is not used in these functions. But could be a 'keep' column to filter off of
#The second column must be X (longitude)
#The third column must be Y (latitude)
head(pointData)
View(pointData)
coords <- colnames(head(pointData)[,2:3])
#They are in the projection 5070, please set x&y coords accordingly
pointSF <- st_as_sf(pointData, coords = coords, crs = proj)
head(pointSF)
head(pointData)
coords <- colnames(head(pointData)[,2:3])
#They are in the projection 5070, please set x&y coords accordingly
pointSF <- st_as_sf(pointData, coords = coords, crs = proj)
head(pointSF)
#Make a dataframe of presence & psuedo abs
#Needs the points simple feature, the blob geojson, and the template raster
pointPseudo <- pseudoFunction(pointSF, blob, temp)
head(pointPseudo) #x&y columns always lat/long
#Make your list of rasters from the document found here (lists can be any length greater than 1):
# https://storage.googleapis.com/predictors_structure/structure.csv
rasterList <- c("terrestrial/gradientmetrics/topo/1km/gm_allvars_topo_ut.tif",
"terrestrial/landfire/topo/1km/lf_allvars_topo_ut.tif",
"terrestrial/landfire/veg/1km/lf_allvars_veg_ut.tif",
"terrestrial/usfws/km_1/usfws_allvars_clim_ut.tif",
"terrestrial/usfws/km_1/usfws_allvars_hydro_ut.tif",
"terrestrial/usfws/km_1/usfws_allvars_veg_ut.tif")
#Run your point data against the rasters
data <- extractStack(pointPseudo, rasterList)
column_names <- colnames(head(data)[,9:ncol(data)])
head(data)
options (warn = - 1)
#set the threshold at which a column is no longer statistically relevant
cut <- 0.95
# declare list of columns to preseve or remove regardless of spearmans. To leave blank use: <- c("")
preserve <- c("gm_hli")
remove <- c("gm_tr")
#remove columns without statistical coorelation, with exception to preserve/remove
cutData <- cutFunction(data, cut, preserve, remove)
head(cutData)
#load in functions
source("SDHMfunctions.R")
#remove columns without statistical coorelation, with exception to preserve/remove
cutData <- cutFunction(data, cut, preserve, remove)
head(cutData)
head(cutData[1])
#remove columns without statistical coorelation, with exception to preserve/remove
cutData <- cutFunction(data, cut, preserve, remove)
spearmans <- cutData[1]
cutData <- cutData[2]
#remove columns without statistical coorelation, with exception to preserve/remove
cutData <- cutFunction(data, cut, preserve, remove)
spearmans <- cutData[1]
cutData <- cutData[2]
View(spearmans)
#remove columns without statistical coorelation, with exception to preserve/remove
cutData <- cutFunction(data, cut, preserve, remove)
spearmans <- cutData[[1]]
View(spearmans)
View(spearmans)
#remove columns without statistical coorelation, with exception to preserve/remove
cutData <- cutFunction(data, cut, preserve, remove)
spearmans <- cutData[[2]]
cutData <- cutData[[1]]
#remove columns without statistical correlation, with exception to preserve/remove
cutF <- cutFunction(data, cut, preserve, remove)
#for checking the output of the spearmans the table is provided here, this is not used in subsequent steps
spearmans <- cutF[[2]]
cutData <- cutF[[1]]
#remove columns without statistical correlation, with exception to preserve/remove
cutF <- cutFunction(data, cut, preserve, remove)
#for checking the output of the spearmans the table is provided here, this is not used in subsequent steps
spearmans <- cutF[[2]]
View(spearmans)
#remove columns without statistical correlation, with exception to preserve/remove
cutF <- cutFunction(data, cut, preserve, remove)
#remove non-data columns
if(nchar(remove[1])>0){
exclude <- names(data) %in% c('FNETID', 'sppres', 'aea_xF','aea_yF', 'cell_aea_x','cell_aea_y','x','y', remove)
} else {
exclude <- names(data) %in% c('FNETID', 'sppres', 'aea_xF','aea_yF', 'cell_aea_x','cell_aea_y','x','y')
}
#test correlation
df1 <- cor(data[!exclude], use = "pairwise.complete.obs", method = "spearman")
#return a dataframe which all that have a correlation above the abs of cut as TRUE
df2 <-subset(df1 > cut | df1 < -cut)
View(df1)
View(df2)
#count the TRUE
df3 <- apply(df2, 1, function(x) length(which(x=="TRUE")))
df4 <- data.frame(t(sapply(df3,c)))
View(df4)
View(df1)
#test correlation
df1 <- cor(data[!exclude], use = "pairwise.complete.obs", method = "spearman") %>% filter(if_any(everything(), ~ !is.na(.)))
View(df1)
#test correlation
df1 <- cor(data[!exclude], use = "pairwise.complete.obs", method = "spearman") %>% filter(if_any(everything(), ~ !is.na(.)))
df1 %>% filter(if_any(everything(), ~ !is.na(.)))
df1 %>% filter_all(any_vars(!is.na(.)))
df1 %>% filter(rowSums(is.na(.)) != ncol(.))
library(dplyr) # data manipulation
df1 %>% filter(rowSums(is.na(.)) != ncol(.))
df1 %>% mutate(indx = row_number()) %>% gather(var, val, -indx) %>% group_by(indx) %>% filter(sum(is.na(val)) != n()) %>% spread(var, val)
library(tidyverse)
df1 %>% mutate(indx = row_number()) %>% gather(var, val, -indx) %>% group_by(indx) %>% filter(sum(is.na(val)) != n()) %>% spread(var, val)
df1 filter(!across(everything(), is.na))
df1 %>% filter(!across(everything(), is.na))
View(df1)
df1 %>% filter(if_any(everything(), ~!is.na(.)))
as.dataframe(df1) %>% filter(if_any(everything(), ~!is.na(.)))
as.data.frame(df1) %>% filter(if_any(everything(), ~!is.na(.)))
df15 <- as.data.frame(df1) %>% filter(if_any(everything(), ~!is.na(.)))
View(df15)
df15[,which(unlist(lapply(df, function(x) !all(is.na(x)))))]
df15 <- df15[,which(unlist(lapply(df, function(x) !all(is.na(x)))))]
View(df15)
#test correlation
df1 <- cor(data[!exclude], use = "pairwise.complete.obs", method = "spearman")
df15 <- as.data.frame(df1) %>% filter(if_any(everything(), ~!is.na(.)))
df15 %>% select_if(all_na)
all_na <- function(x) any(!is.na(x))
df15 %>% select_if(all_na)
df15 <- df15 %>% select_if(all_na)
#test correlation
df1 <- cor(data[!exclude], use = "pairwise.complete.obs", method = "spearman")
#remove na rows
df2 <- as.data.frame(df1) %>% filter(if_any(everything(), ~!is.na(.)))
#remove na columns
all_na <- function(x) any(!is.na(x))
df3 <- df2 %>% select_if(all_na)
View(df3)
#return a dataframe which all that have a correlation above the abs of cut as TRUE
df2 <-subset(df1 > cut | df1 < -cut)
#count the TRUE
df3 <- apply(df2, 1, function(x) length(which(x=="TRUE")))
df4 <- data.frame(t(sapply(df3,c)))
#remove any which appear less than twice (remember all appear once for correlating to themselves)
tempFunc <- function(VEC) max(VEC, na.rm  = TRUE) <= 1 | any(is.na(VEC))
BadCol <- apply(X = df4, MARGIN = 2,  tempFunc)
names <- df4[,!BadCol]
View(names)
#remove non-data columns
if(nchar(remove[1])>0){
exclude <- names(data) %in% c('FNETID', 'sppres', 'aea_xF','aea_yF', 'cell_aea_x','cell_aea_y','x','y', remove)
} else {
exclude <- names(data) %in% c('FNETID', 'sppres', 'aea_xF','aea_yF', 'cell_aea_x','cell_aea_y','x','y')
}
#test correlation
df1 <- cor(data[!exclude], use = "pairwise.complete.obs", method = "spearman")
#remove na rows
df2 <- as.data.frame(df1) %>% filter(if_any(everything(), ~!is.na(.)))
#remove na columns
all_na <- function(x) any(!is.na(x))
df3 <- df2 %>% select_if(all_na)
#return a dataframe which all that have a correlation above the abs of cut as TRUE
df4 <-subset(df3 > cut | df3 < -cut)
View(df4)
#count the TRUE
df3 <- apply(df2, 1, function(x) length(which(x=="TRUE")))
#remove non-data columns
if(nchar(remove[1])>0){
exclude <- names(data) %in% c('FNETID', 'sppres', 'aea_xF','aea_yF', 'cell_aea_x','cell_aea_y','x','y', remove)
} else {
exclude <- names(data) %in% c('FNETID', 'sppres', 'aea_xF','aea_yF', 'cell_aea_x','cell_aea_y','x','y')
}
#test correlation
df1 <- cor(data[!exclude], use = "pairwise.complete.obs", method = "spearman")
#remove na rows
df2 <- as.data.frame(df1) %>% filter(if_any(everything(), ~!is.na(.)))
#remove na columns
all_na <- function(x) any(!is.na(x))
df3 <- df2 %>% select_if(all_na)
#return a dataframe which all that have a correlation above the abs of cut as TRUE
df4 <-subset(df3 > cut | df3 < -cut)
#count the TRUE
df5 <- apply(df4, 1, function(x) length(which(x=="TRUE")))
which(df4$gm_hli == TRUE)
which(df4['gm_hli'] == TRUE)
#return a dataframe which all that have a correlation above the abs of cut as TRUE
df4 <-as.data.frame(subset(df3 > cut | df3 < -cut))
which(df4['gm_hli'] == TRUE)
which(df4$gm_hli == TRUE)
which(df4$gm_cti == TRUE)
print(name)
for (x in colnames(df4)) {
print(name)
}
print(x)
for (x in colnames(df4)) {
print(x)
}
df4$x
for (x in colnames(df4)) {
df4$x
}
df4$paste(x)
for (x in colnames(df4)) {
df4$paste(x)
}
paste('df4$', x)
for (x in colnames(df4)) {
paste('df4$', x)
}
print(paste('df4$', x))
for (x in colnames(df4)) {
print(paste('df4$', x))
}
for (x in colnames(df4)) {
print(paste0('df4$', x))
}
for (x in colnames(df4)) {
print(as.name(paste0('df4$', x)))
}
for (x in colnames(df4)) {
print(assign(paste0('df4$', x)))
}
for (x in colnames(df4)) {
print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
print(df4$gm_hli)
print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x)
print(var)
#print(get(paste0('df4$', x)))
}
print(row.names(var))
for (x in colnames(df4)) {
var <- df4 %>%
select(x)
print(row.names(var))
#print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x) %>%
filter(x = TRUE)
print(var)
#print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x)
sub <- subset(var, TRUE)
print(sub)
#print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x)
sub <- subset(var, x= TRUE)
print(sub)
#print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x)
sub <- subset(var, x != TRUE)
print(sub)
#print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x)
sub <- subset(var, x != 'TRUE')
print(sub)
#print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x) %>%
filter(x != FALSE)
print(var)
#print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x) %>%
filter(x != "FALSE")
print(var)
#print(get(paste0('df4$', x)))
}
var <- df4 %>%
select(x) %>%
filter(get(x) != FALSE)
for (x in colnames(df4)) {
var <- df4 %>%
select(x) %>%
filter(get(x) != FALSE)
print(var)
#print(get(paste0('df4$', x)))
}
for (x in colnames(df4)) {
var <- df4 %>%
select(x) %>%
filter(get(x) != FALSE)
if (row.names(var) != colnames(var)) {
print(var)
}
#print(get(paste0('df4$', x)))
}
